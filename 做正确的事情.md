# 做正确的事情

## 前言

*值得注意的是，当这篇论文的任何部分显得很枯燥时，其中就有一个设计。 -- Richard Steele，《闲谈者》，38页*

我第一次对有限理性这个话题感兴趣是在1983年，在我的第一个AI课程的第一节课的前五分钟。“智力，” Genesereth教授说，“包括成功地完成通常被认为需要智力的任务——学习、推理、计划、沟通、解决问题等等。” 不错，就像这样的介绍。但有些东西缺失了。我是否应该考虑一个问答机的智能，因为它可以通过查找一些大表格中的答案来回答问题? 或者一个理论证明机器智能，因为它的高速度使它能够尝试所有可能的长度增加的证明？作为一个贫穷而又不是特别有知识的研究生，在我看来，在有限的计算和信息资源下，智力与成功的能力密切相关。

幸运的是，许多领域的研究者，包括Michael Genesereth自己，在过去的几十年里都有类似的直觉，而累积的概念发展现在正准备以我们思考人工智能的方式，以及我们构建智能系统的方式来影响一场革命。这本书是作者在变革前提出的，为即将到来的变革提供了一些理性的理由，为新系统的设计提供了一个骨架框架，并描述了一些理论和实用工具，用于在有限的机器中引入智能行为。我还不能提供一种理论来取代传统的完美理性理论，但看来仅仅指出它们作为人工智能的理论基础的不足之处，这似乎是可能的。

这本书假定基本熟悉人工智能的基本概念,包括概率和逻辑,尽管这应该可以通知外行,如果是理想的，除了章4,5和6,可以在第一次阅读 (当然还有后续阅读) 时省略。任何学校的人工智能研究人员都应该找到一些可以反对的东西，哲学家、经济学家和对理性感兴趣的心理学家们将会有一个新的领域。与实时系统有关的计算机科学家和系统设计者可能会发现一些有用的新想法和工具，而国际象棋玩家可能会发现一些新的反对意见。

我的合著者Eric Wefald在1989年8月不幸去世，他和他妻子玛丽在法国度假时发生了车祸。我无法开始表达所有认识他们的人的失落感。Saul Kripke在普林斯顿的时候曾给Eric提供过建议，以他的话说，Eric是一个很有价值的人，同样在家里翻译荷马的作品，或者在元数学中证明定理。在普林斯顿大学哲学博士课程中，他继续在纽约大学任教。他永不满足的好奇心，加上他希望结束他们在地理上的分离，让他和他的妻子一起来到伯克利，并从事人工智能领域的工作。纽约大学的损失是我最大的痛苦; 我可以有把握地说，像他以前的顾问一样，我永远不会有一个更好的学生。这本书的哲学和技术的发展都很大程度上归功于Eric的才华。大部分的工作都是在Eric第一次接触计算机科学和人工智能的两年内完成的，这证明了他的才华。第三章到第六章是他论文的主要部分，尽管还有许多未完成的思路，特别是在第五章和第六章，我一直无法完成。后两章主要是由Eric的笔记、程序注释和1989年机器学习研讨会上的演讲来重建的。

Stuart Russell

加州大学伯克利分校,1991



## 1 有限理性

*爸爸:儿子?*
*MOOKI:爸爸什么?*
*爸爸:我有一些建议给你。*
*MOOKI:那是什么爸爸?*
*爸爸:做正确的事。*
*MOOKI:做正确的事吗?*
*爸爸:是的。*
*MOOKI:就这些吗?*
*爸爸:就是这些。*
*MOOKI:好的。*
*-- Spike Lee，做正确的事。*

智慧和道德似乎与做正确的事有关系。经济学家、哲学家和人工智能研究人员尝试了一些成功的方法，将“正确”变成了一个精确的术语。不幸的是，对任何物理系统的推理能力的不可避免的限制使得在所有的实例中做正确的事情是不可能的。因此，智能系统的设计者需要忘记做正确的事情，而考虑设计正确的系统，乐于知道这个系统有时必须犯错误。正确的系统应该尽可能少地犯错误。这说起来容易做起来难，因为我们会发现，这使得人工智能变得有趣。

### 1.1 人工智能导论

任何一个教一门课程或者写一本和这一章节标题相同的书的人，都必须决定人工智能是什么，即使只是因为好奇的人想知道。以下是一些来自不同文本和专著的“开场白”:

* "人工智能，令人兴奋的新尝试让电脑思考……有头脑的机器，完全和字面意义上的。"（Haugeland, 1985）
* "人工智能是通过使用计算模型来研究心智能力的" (Charniak and McDermott , 1985)
* “人工智能是研究如何让电脑做一些事情，而此时此刻，人们变得更好。” (Rich, 1983)
* “人工智能是对智能行为的研究” (Genesereth and Nilsson, 1987)
* “人工智能是一个研究领域，它试图用计算过程来解释和模拟智能行为。” (Schalkoff , 1990)

我们看到了一系列的定义，从Haugeland的描述, 试图重现人类精神属性的领域——Dennett称之为“有意的立场”——到纯粹的行为方式，只关注表现，(也许是巧妙的)来自Charniak和McDermott的模棱两可的陈述，以及两者之间的Rich。尽管在智能行为方面的定义是不例外的，但它们并没有提供太多的指导。相反，我们可以将人工智能定义为做正确事情的系统设计问题，而不是对各种类型的智能行为进行分类。提供了一个“正确”的定义，这在两方面有帮助:首先，它使我们可以将这种“心智能力”看作是在为找到正确的事情而进行的计划和推理;第二，它为我们这些人腾出了空间(布鲁克斯，1986;阿格尔和查普曼，1987) , 他们认为系统可以做正确的事情而没有这种精神能力。(事实上，做正确事情的多种方式是本书的中心话题)

与其假设一个特定的预定义的和单独指定的认知子系统集合，一个人应该首先考虑智能实体作为一个代理，也就是说一个感知其环境并对其进行操作的系统。这种明显的倒退是至关重要的一步，尤其是因为它迫使我们更加仔细地考虑子系统的规范、边界和相互连接。“整个代理”的方法从需要提供一个完全被标记的三维模型的场景中释放视觉子系统，只用于盲人雕塑家;放松规划系统提供充分详细和有保障的计划的狭窄，只对球员钢琴使用;并且防止诊断系统被设计成只提供最可能的疾病，只对那些真正有普通感冒的人使用，没有更严重的，但可能性更小的。在语言学和哲学领域也有同样的进展。在很大程度上，这些领域已经远离了将句子视为命题的表达，而理性是真正信仰的获取和转化。相反，句子的表达被看作是“言语行为" (Austin, 1962; Grice, 1975; Searle, 1969) 由“定位代理人”(Barwise and Perry, 1983)进行; 理性被看作是感知、行动和动机的一种自适应平衡，而不是一种忠实的“自然之镜” (Rorty, 1979).

然而，如果没有“正确”的定义，Mooki仍处于黑暗之中。这是我们遇到麻烦的地方。理论人工智能研究人员已经研究了经典的、逻辑上的实用推理定义，认为这是一种能够实现特定目标的行动，可能是麦卡锡(McCarthy)(1958)早期设计的一项能够证明其通往机场的程序的早期设计。一些人采取了更为灵活的理性的决策理论定义，从经济学角度出发，正确的做法是使预期收益最大化(冯·诺依曼，1947)。通过这些定义，加上适当编码的知识使它们得以应用，人工智能研究人员已经减少了最初的问题，即创建智能的可能只是一系列棘手的实现问题。道尔的“理性心理学”建议(1983)令人信服地论证了人工智能应该、也将会将自己从认知心理学和计算机科学中分离出来，将注意力集中在理性系统抽象设计的核心问题上，包括理性的形成和信念、欲望和意图的转变。

我们将在下一节讨论逻辑和决策理论模型的确有缺陷。简单地说，所有这些方法都抽象出了做正确事情的过程的一个关键方面，即把“对”与最终采取的行动联系起来，而不是整个思考和行动的过程。当仅仅是有限的机器试图计算非平凡环境中的理论模型的建议时，这种差异是至关重要的，因为这些建议可以任意决定。通过关注整个过程，我们可以得出一个人工智能的问题陈述，避免了经典方法的困难。这一章和后续章节讨论了问题的陈述，并将其运用到设计体系结构和算法的直觉中更适合那些不具有无限速度的机器。我们的方法的重点是推理系统对自己的讨论进行推理的能力，以便尽可能地利用有限的计算资源。我们的研究结果表明这种能力是有用的。

### 1.2 代理、架构和程序

智能系统作为代理的观点关注的是系统与环境之间的交互作用。一个代理可以抽象地描述为一个映射，不一定是有限的，从感觉输入(或“感知”)到当前时间，到代理响应的动作。也就是说，对于每一个可能的感知序列，映射状态下的代理将采取响应，如图1.1所示。例如，可以抽象地描述一个国际象棋程序，它可以根据一系列动作产生的给定位置来表示它的移动。行为的标准规范模型，无论是逻辑的还是决策的，都应该被看作是对这个映射的约束。这些约束说，粗略地说，考虑到因其感知的序列而赋予代理的信念和目标，所选择的行动应该是根据信念实现目标的行为;或者在概率和效用的语言中有一些等价的表达式。因此，一个合理的国际象棋程序，如果有获胜的目标，对象棋规则的知识，以及对当前位置的感知，就应该以这样一种方式来保证一场胜利。本节和下一节将讨论两个概念:首先，在映射和实现作为在某些硬件上运行的程序之间存在一个重要的区别;其次，在映射上放置合理性约束是不合适的，因为这是我们所关心的实现的行为。

有三种不同的方式来考虑一个代理。第一个是从感知序列到动作的映射;第二个实现它的程序;第三是程序运行时的行为。程序和它们实现的映射之间的关系是计算机科学的基础。映射是一个完全抽象的实体; 例如，如果感知序列的长度是无界的，那么映射将是无限的，而代理程序总是有限的。可计算性理论是关于哪种类型的映射可以用哪种类型的程序(或程序/机器组合)来表示;显然，只有一些无限映射的集合可以用一个有限的程序来表示，因为有可能比有限的程序有更多的无限的映射。

未能观察到映射及其实现之间的区别是1970年的程序声明性争议的一个原因，其中声明性立场的主要动机是，知识的逻辑公理提供了映射的明确规范，而程序视图则更多地关注于它在程序中的实现。Doyle(1983)正确地论证了这些位置不是不一致的，因为一个过程的实现完全能够代表一个逻辑上指定的映射。许多同样的问题在最近的辩论中也出现了，辩论的支持者和反应性的行动选择方法(Brooks, 1986; Agre and Chapman , 1987) 后一种争论在许多方面都是对前者的一种重复。声明性/协商性的位置以与规范约束相同的方式实现映射:明确的目标和信念结构通过推理过程来考虑，以选择操作。程序/反应性的立场是，所有这些考虑都是浪费时间——为什么我们不构建“做正确的事情”的代理呢? 在这个和后面的部分中，我们非正式地讨论了由于设计问题的性质而产生的额外的约束，使得它远远不能简单地完成。事实上，这些约束表明需要对映射进行混合表示，包括声明性知识和直接表。

我们将从一个非常抽象的设计约束规范开始，以避免过度承诺可能导致系统不足;与此同时，重要的是要理解智力的区别特征，这限制了实现的选择，使它不仅仅是一种美学或任务特定的工程。代理设计问题涉及到架构和程序:

* 架构M是代理程序的固定解释器。在执行这个程序时，架构从环境中提取原始的感知(例如，像素或击键)，运行程序以获得输出(例如，马达命令或在终端上的字符)。因此，体系结构也为代理程序定义了编程语言L，即体系结构将运行的所有程序集。
* 一个代理程序l ∈ L是感知-动作映射的有效表示。更准确地说，当它在架构上运行时，当代理接收到特定的感知序列时，它会产生特定的动作。它是一个持续运行的例程，而不是一个简单的“一次性”程序，它接受一个感知序列作为输入并生成一个动作。形式上，我们可以把它描述为一个函数f: P* -> a, P是一组感知，P*是所有可能的感知序列的集合，a是代理可以在外部世界进行的一系列可能的动作。